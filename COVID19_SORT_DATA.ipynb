{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import random \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'C:\\\\Users\\\\pacol\\\\Desktop\\\\GIT\\\\COVID19\\\\data\\\\'\n",
    "NOR_DIR = DATA_PATH + 'New Data\\\\NORMAL'\n",
    "PNE_DIR = DATA_PATH + 'New Data\\\\PNEUMONIA'\n",
    "COV_DIR = DATA_PATH + 'New Data\\\\COVID-19'\n",
    "\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_HEIGHT = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    data_nor = []\n",
    "    data_pne = []\n",
    "    data_cov = []\n",
    "    data_covaug = []\n",
    "\n",
    "    \n",
    "    for img in tqdm(os.listdir(NOR_DIR)):  \n",
    "\n",
    "        \n",
    "        path = os.path.join(NOR_DIR,img)\n",
    "        img = cv2.imread(path)\n",
    "        try:\n",
    "            img = cv2.resize(img, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            data_nor.append(img)\n",
    "                \n",
    "        except cv2.error as e:\n",
    "            print('Invalid frame!')\n",
    "        cv2.waitKey()\n",
    "            \n",
    "            \n",
    "            \n",
    "    for img in tqdm(os.listdir(PNE_DIR)):\n",
    "        \n",
    "        path = os.path.join(PNE_DIR,img)\n",
    "        img = cv2.imread(path)\n",
    "        try:\n",
    "            img = cv2.resize(img, (IMAGE_WIDTH,IMAGE_HEIGHT))         \n",
    "            data_pne.append(img)\n",
    "        except cv2.error as e:\n",
    "            print('Invalid frame!')\n",
    "        cv2.waitKey()\n",
    "        \n",
    "        \n",
    "    for img in tqdm(os.listdir(COV_DIR)):\n",
    "        \n",
    "        path = os.path.join(COV_DIR,img)\n",
    "        img = cv2.imread(path)\n",
    "        #Rotate\n",
    "        rotate=iaa.Affine(rotate=(-15, 15))\n",
    "        rotated_image=rotate.augment_image(img)\n",
    "        #Noise\n",
    "        gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
    "        noise_image=gaussian_noise.augment_image(img)\n",
    "        #Cropping image\n",
    "        crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
    "        corp_image=crop.augment_image(img)\n",
    "        #flipping image horizontally\n",
    "        flip_hr=iaa.Fliplr(p=1.0)\n",
    "        flip_hr_image= flip_hr.augment_image(img)\n",
    "        #Rescale\n",
    "        scale_im=iaa.Affine(scale={\"x\": (1.5, 1.0), \"y\": (1.5, 1.0)})\n",
    "        scale_image =scale_im.augment_image(img)\n",
    "\n",
    "        try:\n",
    "            img = cv2.resize(img, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            img = cv2.resize(rotated_image, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            img = cv2.resize(noise_image, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            img = cv2.resize(corp_image, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            img = cv2.resize(flip_hr_image, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            img = cv2.resize(scale_image, (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "            data_cov.append(img)\n",
    "            data_covaug.append(img)\n",
    "            data_covaug.append(rotated_image)\n",
    "            data_covaug.append(noise_image)\n",
    "            data_covaug.append(corp_image)\n",
    "            data_covaug.append(flip_hr_image)\n",
    "            data_covaug.append(scale_image)\n",
    "        except cv2.error as e:\n",
    "            print('Invalid frame!')\n",
    "        cv2.waitKey()\n",
    "\n",
    "\n",
    "    shuffle(data_nor)\n",
    "    shuffle(data_pne)\n",
    "    shuffle(data_cov)\n",
    "    shuffle(data_covaug)\n",
    "    return data_nor, data_pne, data_cov, data_covaug\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1341/1341 [00:15<00:00, 86.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1345/1345 [00:17<00:00, 75.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 219/219 [00:28<00:00,  7.79it/s]\n"
     ]
    }
   ],
   "source": [
    "data_nor, data_pne, data_cov, data_covaug = create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(0.2*len(data_nor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(data_nor, data_pne, data_covaug, data_cov, coef_val, coef_test):\n",
    "    \n",
    "    #Paths for no data augmentation\n",
    "    \n",
    "    NOR_TRAIN_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\train\\\\NORMAL'\n",
    "    NOR_TEST_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\test\\\\NORMAL'\n",
    "    NOR_VAL_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\val\\\\NORMAL'\n",
    "    PNE_TRAIN_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\train\\\\PNEUMONIA'\n",
    "    PNE_TEST_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\test\\\\PNEUMONIA'\n",
    "    PNE_VAL_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\val\\\\PNEUMONIA'\n",
    "    COV_TRAIN_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\train\\\\COVID-19'\n",
    "    COV_TEST_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\test\\\\COVID-19'\n",
    "    COV_VAL_DIR0 = DATA_PATH + 'Sorted Data (No Aug)\\\\val\\\\COVID-19'\n",
    "    \n",
    "    #Paths for data augmentation\n",
    "    \n",
    "    NOR_TRAIN_DIR = DATA_PATH + 'Sorted Data\\\\train\\\\NORMAL'\n",
    "    NOR_TEST_DIR = DATA_PATH + 'Sorted Data\\\\test\\\\NORMAL'\n",
    "    NOR_VAL_DIR = DATA_PATH + 'Sorted Data\\\\val\\\\NORMAL'\n",
    "    PNE_TRAIN_DIR = DATA_PATH + 'Sorted Data\\\\train\\\\PNEUMONIA'\n",
    "    PNE_TEST_DIR = DATA_PATH + 'Sorted Data\\\\test\\\\PNEUMONIA'\n",
    "    PNE_VAL_DIR = DATA_PATH + 'Sorted Data\\\\val\\\\PNEUMONIA'\n",
    "    COV_TRAIN_DIR = DATA_PATH + 'Sorted Data\\\\train\\\\COVID-19'\n",
    "    COV_TEST_DIR = DATA_PATH + 'Sorted Data\\\\test\\\\COVID-19'\n",
    "    COV_VAL_DIR = DATA_PATH + 'Sorted Data\\\\val\\\\COVID-19'\n",
    "    \n",
    "\n",
    "    \n",
    "    #*****************NORMAL*******************\n",
    "   \n",
    "    lim_test = round(coef_test*len(data_nor))\n",
    "    \n",
    "    train_data_nor = data_nor[0:len(data_nor)-lim_test]\n",
    "    test_data_nor = data_nor[len(data_nor)-lim_test:len(data_nor)]\n",
    "    \n",
    "    lim_val = round(coef_val*len(train_data_nor))\n",
    "    \n",
    "    val_data_nor = data_nor[len(train_data_nor)-lim_val:len(train_data_nor)]\n",
    "    train_data_nor = data_nor[0:len(train_data_nor)-lim_val]\n",
    "    \n",
    "    #We copy the images into a new directory so we can use a data generator\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    for img in train_data_nor:\n",
    "        count=count+1\n",
    "        os.chdir(NOR_TRAIN_DIR) \n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img) \n",
    "        os.chdir(NOR_TRAIN_DIR0)\n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img)\n",
    "    \n",
    "    count=0\n",
    "    for img in test_data_nor: \n",
    "        count=count+1\n",
    "        os.chdir(NOR_TEST_DIR)\n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img) \n",
    "        os.chdir(NOR_TEST_DIR0)\n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img) \n",
    "     \n",
    "    count=0\n",
    "    for img in val_data_nor:\n",
    "        count=count+1\n",
    "        os.chdir(NOR_VAL_DIR)\n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img)         \n",
    "        os.chdir(NOR_VAL_DIR0)\n",
    "        cv2.imwrite('Normal'+str(count) +'.jpg', img)\n",
    "        \n",
    "    #*****************PNEUMONIA*******************\n",
    "    \n",
    "    lim_test = round(coef_test*len(data_pne))\n",
    "    \n",
    "    train_data_pne = data_pne[0:len(data_pne)-lim_test]\n",
    "    test_data_pne = data_pne[len(data_pne)-lim_test:len(data_pne)]\n",
    "    \n",
    "    lim_val = round(coef_val*len(train_data_pne))\n",
    "    \n",
    "    val_data_pne = data_pne[len(train_data_pne)-lim_val:len(train_data_pne)]\n",
    "    train_data_pne = data_pne[0:len(train_data_pne)-lim_val]\n",
    "    \n",
    "    #We copy the images into a new directory so we can use a data generator\n",
    "    \n",
    "    \n",
    "    count=0\n",
    "    for img in train_data_pne:\n",
    "        count=count+1\n",
    "        os.chdir(PNE_TRAIN_DIR) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img) \n",
    "        os.chdir(PNE_TRAIN_DIR0) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img)\n",
    "    \n",
    "    count=0\n",
    "    for img in test_data_pne:\n",
    "        count=count+1\n",
    "        os.chdir(PNE_TEST_DIR) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img) \n",
    "        os.chdir(PNE_TEST_DIR0) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img) \n",
    "    \n",
    "    count=0\n",
    "    for img in val_data_pne:\n",
    "        count=count+1\n",
    "        os.chdir(PNE_VAL_DIR) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img) \n",
    "        os.chdir(PNE_VAL_DIR0) \n",
    "        cv2.imwrite('Pneumonia'+str(count) +'.jpg', img)\n",
    "\n",
    "    #*****************COVID-19 With Aug*******************\n",
    "    \n",
    "    lim_test = round(coef_test*len(data_covaug))\n",
    "    \n",
    "    train_data_cov = data_covaug[0:len(data_covaug)-lim_test]\n",
    "    test_data_cov = data_covaug[len(data_covaug)-lim_test:len(data_covaug)]\n",
    "    \n",
    "    lim_val = round(coef_val*len(train_data_cov))\n",
    "    \n",
    "    val_data_cov = data_covaug[len(train_data_cov)-lim_val:len(train_data_cov)]\n",
    "    train_data_cov = data_covaug[0:len(train_data_cov)-lim_val]\n",
    "    \n",
    "    #We copy the images into a new directory so we can use a data generator\n",
    "    \n",
    "    os.chdir(COV_TRAIN_DIR) \n",
    "    count=0\n",
    "    for img in train_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img) \n",
    "        \n",
    "    os.chdir(COV_TEST_DIR) \n",
    "    count=0\n",
    "    for img in test_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img) \n",
    "\n",
    "    os.chdir(COV_VAL_DIR) \n",
    "    count=0\n",
    "    for img in val_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img)         \n",
    "        \n",
    "        \n",
    "    #*****************COVID-19 With Aug*******************\n",
    "    \n",
    "    lim_test = round(coef_test*len(data_cov))\n",
    "    \n",
    "    train_data_cov = data_cov[0:len(data_cov)-lim_test]\n",
    "    test_data_cov = data_cov[len(data_cov)-lim_test:len(data_cov)]\n",
    "    \n",
    "    lim_val = round(coef_val*len(train_data_cov))\n",
    "    \n",
    "    val_data_cov = data_cov[len(train_data_cov)-lim_val:len(train_data_cov)]\n",
    "    train_data_cov = data_cov[0:len(train_data_cov)-lim_val]\n",
    "    \n",
    "    #We copy the images into a new directory so we can use a data generator\n",
    "    \n",
    "    os.chdir(COV_TRAIN_DIR0) \n",
    "    count=0\n",
    "    for img in train_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img) \n",
    "        \n",
    "    os.chdir(COV_TEST_DIR0) \n",
    "    count=0\n",
    "    for img in test_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img) \n",
    "\n",
    "    os.chdir(COV_VAL_DIR0) \n",
    "    count=0\n",
    "    for img in val_data_cov:\n",
    "        count=count+1\n",
    "        cv2.imwrite('Covid'+str(count) +'.jpg', img)      \n",
    "           \n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_test = 0.2\n",
    "coef_val = 0.2\n",
    "sort_data(data_nor, data_pne, data_covaug, data_cov, coef_val, coef_test, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1341"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(len(data_nor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size):\n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "    BATCH_SIZE = batch_size\n",
    "    IMAGE_SIZE=128\n",
    "    IMAGE_SIZE_V=(IMAGE_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    train_dir = DATA_PATH + 'Sorted Data\\\\train'\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = IMAGE_SIZE_V,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "    test_dir = DATA_PATH + 'Sorted Data\\\\test'\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size = IMAGE_SIZE_V,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "\n",
    "    val_dir = DATA_PATH + 'Sorted Data\\\\val'\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size = IMAGE_SIZE_V,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "    \n",
    "    return train_generator, test_generator, val_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2560 images belonging to 3 classes.\n",
      "Found 800 images belonging to 3 classes.\n",
      "Found 640 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "\n",
    "train_generator, test_generator, val_generator = data_generator(batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
